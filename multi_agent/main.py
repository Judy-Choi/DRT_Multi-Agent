#!/usr/bin/env python3
"""
DRT Multi-Agent ë²ˆì—­ ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ íŒŒì¼

í•œêµ­ì–´ ë¬¸ì¥ì„ ì…ë ¥ë°›ì•„ multi-agent í˜‘ì—…ì„ í†µí•´ 
ê³ í’ˆì§ˆ ì˜ì–´ ë²ˆì—­ê³¼ thinking traceë¥¼ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import logging
import json
import os
import time
import argparse
from typing import Dict
from dotenv import load_dotenv
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed


from graph.state import State
from graph.graph_controller import DRT
from graph.visualize import visualize_and_save_graph

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

def run_multi_agent(drt, sentence: str) -> Dict[str, str]:
    """DRT Multi-Agent ì‹¤í–‰"""
    initial_state = State()
    initial_state.sentence = sentence
    
    final_state = drt.graph.invoke(initial_state)
    
    return final_state 


def process_single_sentence(drt, test_sentence):
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""    
    result = run_multi_agent(drt, test_sentence)

    triplet = {
        "text": result['sentence'],
        "trans": result["translations"][-1],
        "thought": result["thought"]
    }

    print(triplet)

    return triplet


def process_batch(drt, sentences_batch, batch_idx):
    """ë¬¸ì¥ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    batch_triplets = []
    
    for i, sentence in enumerate(sentences_batch):
        try:
            logger.info(sentence)
            result = run_multi_agent(drt, sentence)

            # ê°•ì œë¡œ ì‰¼ (API ì‚¬ìš©ëŸ‰ ì œí•œ ê±¸ë¦¼)
            time.sleep(1)

            # ë§Œì•½ thought ê°€ ë¹„ì–´ìˆë‹¤ë©´ ë°˜ë³µ íšŸìˆ˜ë¥¼ ë„˜ì–´ì„œ ê°•ì œ ì¢…ë£Œëœ ê²ƒ.
            # ë”°ë¼ì„œ ì´ triplet ì€ íŒŒì¼ì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            if result["thought"] == "":
                logger.warning(f"ë°°ì¹˜ {batch_idx}, ë¬¸ì¥ {i+1}: thoughtê°€ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœ€")
                continue
            
            triplet = {
                "text": result['sentence'],
                "trans": result["translations"][-1],
                "thought": result["thought"]
            }

            print(f"[ë°°ì¹˜ {batch_idx}] {triplet}")
            batch_triplets.append(triplet)
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ {batch_idx}, ë¬¸ì¥ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    return batch_triplets


def process_json_file(drt, json_path, run_step):
    """JSON íŒŒì¼ì—ì„œ í•œêµ­ì–´ ë¬¸ì¥ë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        korean_sentences = []
        
        # JSON êµ¬ì¡° ë¶„ì„ ë° í•œêµ­ì–´ ë¬¸ì¥ ì¶”ì¶œ
        if isinstance(data, list):
            for item in data:
                if isinstance(item, dict) and "ko" in item:
                    korean_sentences.append(item["ko"])

        # ë³€ìˆ˜ ì •ì˜
        output_file = f"data/drt_triplet_{run_step}.json"
        # ë°°ì¹˜ í¬ê¸°ì™€ ë™ì‹œ ì‹¤í–‰ ì›Œì»¤ ìˆ˜ ì„¤ì •
        batch_size = 10  # í•œ ë°°ì¹˜ë‹¹ ë¬¸ì¥ ìˆ˜
        max_workers = 8   # ë™ì‹œ ì‹¤í–‰í•  ë°°ì¹˜ ìˆ˜

        start_i = batch_size * max_workers * (run_step - 1)
        end_i = batch_size * max_workers * run_step

        korean_sentences = korean_sentences[start_i:end_i]

        logger.info(f"ğŸ“Š RUN_STEP: {run_step}")
        logger.info(f"ğŸ“Š ì´ {len(korean_sentences)}ê°œì˜ ë¬¸ì¥ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        logger.info(f"ğŸ”„ ë°°ì¹˜ í¬ê¸°: {batch_size}, ë™ì‹œ ì‹¤í–‰ ì›Œì»¤: {max_workers}")
        
        # # ë¬¸ì¥ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        batches = []
        for i in range(0, len(korean_sentences), batch_size):
            batch = korean_sentences[i:i + batch_size]
            batches.append((batch, i // batch_size + 1))
        
        logger.info(f"ğŸ“¦ ì´ {len(batches)}ê°œì˜ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.")
        
        # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        all_triplets = []
        
        # ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  ë°°ì¹˜ë¥¼ ë™ì‹œì— ì œì¶œ
            future_to_batch = {
                executor.submit(process_batch, drt, batch, batch_idx): (batch, batch_idx)
                for batch, batch_idx in batches
            }
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            with tqdm(total=len(batches), desc="ë°°ì¹˜ ì²˜ë¦¬ ì¤‘") as pbar:
                for future in as_completed(future_to_batch):
                    batch, batch_idx = future_to_batch[future]
                    try:
                        batch_triplets = future.result()
                        all_triplets.extend(batch_triplets)
                        logger.info(f"âœ… ë°°ì¹˜ {batch_idx} ì™„ë£Œ: {len(batch_triplets)}ê°œ triplet ìƒì„±")
                        
                            
                    except Exception as e:
                        logger.error(f"âŒ ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                    finally:
                        pbar.update(1)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_triplets, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ’¾ ëª¨ë“  ë²ˆì—­ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logger.info(f"ğŸ“Š ì´ {len(all_triplets)}ê°œì˜ tripletì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    
    except FileNotFoundError:
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
    except Exception as e:
        logger.error(f"âŒ JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""    
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='DRT Multi-Agent ë²ˆì—­ ì‹œìŠ¤í…œ')
    parser.add_argument('--run_step', type=int, default=1, 
                       help='ì‹¤í–‰í•  ìŠ¤í… ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)')
    
    args = parser.parse_args()
    run_step = args.run_step
    
    logger.info("ğŸš€ DRT Multi-Agent ë²ˆì—­ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    logger.info(f"ğŸ“Š RUN_STEP: {run_step}")
    
    # DRT ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    logger.info("ğŸ“Š DRT ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
    drt = DRT()
    
    # ê·¸ë˜í”„ ì‹œê°í™” ë° PNG ì €ì¥
    logger.info("ğŸ¨ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ëŠ” ì¤‘...")
    visualize_and_save_graph(drt.graph, save_path="agent_graph.png")     

    # GOOD
    # test_sentence = "ì´ ì •ë„ ê³¼ì œëŠ” ì‹ì€ ì£½ ë¨¹ê¸°ì•¼."

    # BAD
    # test_sentence = "ë‚˜ëŠ” ë‚¨ì ë³´ëŠ” ëˆˆì´ ë†’ì•„ìš”"
    # test_sentence = "ë‚˜ëŠ” ì°¨ì€ìš°ì™€ í™”ì´‰ì„ ë°íŒë‹¤."  
    # test_sentence = "ê°„ë°œì˜ ì°¨ì´ë¡œ í•©ê²©ì´ í™•ì •ëë‹¤."

    # logger.info("ğŸ“ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    # process_single_sentence(drt, test_sentence)

    logger.info("ğŸ“ JSON íŒŒì¼ì—ì„œ ë¬¸ì¥ë“¤ì„ ì½ì–´ì„œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    kiss_json_path = "data/kiss.json"
    
    process_json_file(drt, kiss_json_path, run_step)

    
    logger.info("âœ¨ ë²ˆì—­ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")



if __name__ == "__main__":
    main() 